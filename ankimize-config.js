// Configuración estática para Ankimize
window.ANKIMIZE_CONFIG = {
  isStatic: true,
  apiEndpoint: null,
  articles: {
    "1": {
  "title": "Inteligencia Artificial: Conceptos Fundamentales",
  "source": "Wikipedia",
  "content": "# Inteligencia Artificial: Conceptos Fundamentales\n\nLa Inteligencia Artificial (IA) es una rama de la informática que busca desarrollar máquinas capaces de imitar comportamientos inteligentes. Estas máquinas pueden aprender de la experiencia, adaptarse a nuevas situaciones y realizar tareas que tradicionalmente requerirían inteligencia humana.\n\n## Fundamentos y Definiciones\n\nEl término \"Inteligencia Artificial\" fue acuñado por John McCarthy en 1956 durante la conferencia de Dartmouth, considerada el evento fundacional de la IA como campo de estudio. McCarthy definió la IA como \"la ciencia e ingeniería de hacer máquinas inteligentes\".\n\nLa IA puede clasificarse en dos categorías principales:\n\n- **IA débil o estrecha**: Sistemas diseñados para realizar tareas específicas sin consciencia real (como asistentes virtuales, sistemas de recomendación, etc.)\n- **IA fuerte o general**: Sistemas hipotéticos con una inteligencia comparable a la humana, capaces de comprender, aprender y aplicar conocimientos en diversos dominios\n\nActualmente, todos los sistemas de IA existentes pertenecen a la categoría de IA débil.\n\n## Machine Learning\n\nEl aprendizaje automático, o Machine Learning, es un subcampo de la IA que se centra en desarrollar algoritmos que permiten a las computadoras aprender patrones a partir de datos. A diferencia de la programación tradicional, donde se definen explícitamente las reglas, en el Machine Learning los sistemas mejoran automáticamente con la experiencia.\n\nLos principales enfoques de Machine Learning incluyen:\n\n- **Aprendizaje supervisado**: El algoritmo aprende a partir de datos etiquetados, donde la respuesta correcta está proporcionada\n- **Aprendizaje no supervisado**: El algoritmo busca patrones en datos no etiquetados\n- **Aprendizaje por refuerzo**: El algoritmo aprende mediante un sistema de recompensas y penalizaciones\n\n## Deep Learning\n\nEl aprendizaje profundo o Deep Learning es una técnica avanzada de Machine Learning que utiliza redes neuronales artificiales con múltiples capas (de ahí \"profundo\"). Estas redes están inspiradas en la estructura del cerebro humano y han revolucionado campos como el reconocimiento de imágenes, el procesamiento del lenguaje natural y la traducción automática.\n\nEl Deep Learning ha logrado avances significativos gracias a tres factores principales:\n\n1. Disponibilidad de grandes cantidades de datos de entrenamiento\n2. Mejoras en la potencia de cómputo (especialmente GPUs)\n3. Avances en algoritmos y arquitecturas de redes neuronales\n\n## Ética en la IA\n\nLa ética en la IA es un campo emergente y crucial que aborda los impactos sociales, legales y morales del desarrollo y uso de sistemas de inteligencia artificial. Algunos de los problemas éticos más importantes incluyen la privacidad de datos, los sesgos algorítmicos, la transparencia de los sistemas, la responsabilidad por decisiones automatizadas y el impacto de la IA en el empleo.\n\nLos principios éticos más comúnmente discutidos en IA incluyen:\n\n- **Beneficencia**: Las IA deben actuar en beneficio de las personas\n- **No maleficencia**: Las IA no deben causar daño\n- **Autonomía**: Las IA deben respetar la libertad de elección de las personas\n- **Justicia**: Los beneficios y cargas de la IA deben distribuirse equitativamente\n- **Explicabilidad**: Las decisiones de la IA deben ser comprensibles\n\n## Aplicaciones de la Inteligencia Artificial\n\nLa IA tiene aplicaciones en prácticamente todos los campos imaginables. En la medicina, se utiliza para diagnósticos más precisos, descubrimiento de fármacos y personalización de tratamientos. En finanzas, algoritmos de IA detectan fraudes, optimizan inversiones y evalúan riesgos crediticios.\n\nLos sistemas de IA también están transformando el transporte con vehículos autónomos, la educación con sistemas de tutoría adaptativa, y la manufactura con robots inteligentes. En nuestra vida cotidiana, interactuamos con IA a través de asistentes virtuales, recomendaciones personalizadas y filtros de spam.\n\n## Desafíos y Limitaciones\n\nA pesar de los avances, la IA enfrenta importantes desafíos, como:\n\n- **Interpretabilidad**: Muchos modelos avanzados de IA (especialmente deep learning) funcionan como \"cajas negras\", donde es difícil entender cómo llegan a sus conclusiones\n- **Generalización**: Los sistemas actuales son excelentes en tareas específicas pero tienen dificultades para transferir conocimientos entre dominios\n- **Razonamiento causal**: La IA actual es buena encontrando correlaciones pero no comprende relaciones causales\n- **Sentido común**: Los humanos tenemos un conocimiento implícito del mundo que es difícil de codificar en los sistemas de IA\n\n## El Futuro de la IA\n\nLas investigaciones actuales en IA buscan superar estas limitaciones a través de enfoques como el aprendizaje por transferencia, el aprendizaje auto-supervisado, la IA neurosimbólica (que combina el aprendizaje profundo con representaciones simbólicas) y la IA inspirada en la neurociencia.\n\nMuchos expertos consideran que estamos lejos de lograr una Inteligencia Artificial General, aunque existe debate sobre el cronograma y la viabilidad de este objetivo. Mientras tanto, la IA seguirá transformando numerosos aspectos de nuestra sociedad, economía y vida cotidiana, planteando tanto oportunidades como desafíos que deberemos abordar colectivamente."
},
    "2": {
  "title": "Historia de Internet: Orígenes y Evolución",
  "source": "Wikipedia",
  "content": "# Historia de Internet: Orígenes y Evolución\n\nInternet es una red global de computadoras interconectadas que ha revolucionado la comunicación y el acceso a la información en todo el mundo. Su historia es un fascinante relato de innovación, colaboración y transformación tecnológica.\n\n## Los Orígenes: ARPANET\n\nLos orígenes de Internet se remontan a la década de 1960, en plena Guerra Fría. En 1969, la Agencia de Proyectos de Investigación Avanzada de Defensa de Estados Unidos (DARPA) creó ARPANET, una red experimental diseñada para permitir la comunicación entre centros de investigación militares y universidades que trabajaban en proyectos de defensa.\n\nUno de los objetivos principales de ARPANET era crear una red de comunicaciones descentralizada que pudiera seguir funcionando incluso si parte de ella fuera destruida en un ataque militar. Esta característica de diseño sentó las bases para la estructura distribuida que caracteriza a Internet en la actualidad.\n\nEl 29 de octubre de 1969 se produjo la primera conexión entre dos computadoras: una en la Universidad de California en Los Ángeles (UCLA) y otra en el Instituto de Investigación de Stanford. Este evento, considerado el nacimiento de Internet, permitió enviar el mensaje \"LOGIN\", aunque el sistema se bloqueó después de transmitir solo las primeras dos letras, \"LO\".\n\n## Desarrollo de los Protocolos TCP/IP\n\nEn los años 70, ARPANET seguía creciendo, pero surgió un problema fundamental: las diferentes redes de computadoras utilizaban protocolos de comunicación incompatibles entre sí. Para resolver este desafío, los investigadores Vinton Cerf y Robert Kahn desarrollaron en 1974 el Protocolo de Control de Transmisión (TCP) y el Protocolo de Internet (IP), conocidos conjuntamente como TCP/IP.\n\nTCP/IP permitió que redes heterogéneas pudieran comunicarse entre sí, estableciendo un lenguaje común para la transmisión de datos. Estos protocolos se convirtieron en el estándar oficial de ARPANET en 1983, momento que muchos consideran como el verdadero nacimiento de Internet tal como la conocemos hoy.\n\n## De ARPANET a Internet\n\nEn la década de 1980, ARPANET se dividió en dos redes: una militar (MILNET) y otra académica que conservó el nombre de ARPANET. Esta última, junto con otras redes que utilizaban TCP/IP, formaron el núcleo de lo que empezó a llamarse \"Internet\".\n\nLa adopción de TCP/IP por parte de la Fundación Nacional de Ciencia de EE.UU. (NSF) para su red NSFNET en 1985 fue un momento crucial, ya que conectó cinco centros de supercomputación y posteriormente se expandió para incluir redes académicas de todo Estados Unidos.\n\nA finales de los 80, Internet comenzó a extenderse internacionalmente, conectando universidades y centros de investigación en Europa, Australia y Japón. Sin embargo, su uso seguía limitado principalmente a la comunidad académica y científica.\n\n## El Nacimiento de la World Wide Web\n\nEl verdadero punto de inflexión para la popularización de Internet llegó en 1989, cuando Tim Berners-Lee, un científico del CERN (Organización Europea para la Investigación Nuclear), propuso la World Wide Web (WWW). Berners-Lee desarrolló los tres elementos fundamentales de la web:\n\n- HTML (HyperText Markup Language): el lenguaje para crear páginas web\n- HTTP (HyperText Transfer Protocol): el protocolo para transmitir páginas web\n- URLs (Uniform Resource Locators): el sistema de direcciones para localizar recursos en la web\n\nEn 1991, el CERN publicó el primer sitio web del mundo y liberó el código de la WWW de forma gratuita, permitiendo que cualquiera pudiera utilizarlo y mejorarlo. Esto sentó las bases para la explosión de contenido y servicios que caracterizaría a Internet en los años siguientes.\n\n## La Expansión Comercial\n\nA principios de los años 90, Internet comenzó su transición de una red académica a una plataforma comercial. En 1991, la NSF eliminó las restricciones sobre el uso comercial de Internet, abriendo la puerta a empresas y particulares.\n\nEl desarrollo de navegadores web accesibles fue fundamental para esta expansión. En 1993, el navegador Mosaic, creado por Marc Andreessen y Eric Bina en el Centro Nacional de Aplicaciones de Supercomputación (NCSA), introdujo una interfaz gráfica amigable que permitía visualizar imágenes junto con texto. Mosaic evolucionó posteriormente en Netscape Navigator, el navegador dominante de mediados de los 90.\n\nEn 1995, Microsoft lanzó Internet Explorer, iniciando la llamada \"guerra de navegadores\" que aceleró el desarrollo y la adopción de tecnologías web. Para ese momento, Internet contaba con aproximadamente 16 millones de usuarios en todo el mundo.\n\n## Desafíos Actuales\n\nA pesar de su impacto revolucionario, Internet enfrenta importantes desafíos:\n\n- **Brecha digital**: Aunque más de la mitad de la población mundial está conectada, persisten importantes desigualdades en el acceso y uso de Internet.\n- **Privacidad y seguridad**: La recopilación masiva de datos personales y las amenazas cibernéticas plantean riesgos significativos.\n- **Desinformación**: La proliferación de noticias falsas y contenido engañoso amenaza el discurso democrático.\n- **Concentración de poder**: Un pequeño número de empresas tecnológicas ejerce un control sin precedentes sobre la infraestructura digital global.\n\n## El Futuro de Internet\n\nLas tecnologías emergentes como 5G, computación cuántica, realidad virtual/aumentada y blockchain apuntan hacia un Internet aún más rápido, inmersivo y descentralizado. Iniciativas como Web3 buscan devolver el control de los datos a los usuarios y reducir la dependencia de plataformas centralizadas.\n\nLa visión original de Internet como una red abierta, colaborativa y distribuida sigue siendo relevante mientras navegamos los desafíos actuales y las oportunidades futuras de la era digital."
}
  }
};